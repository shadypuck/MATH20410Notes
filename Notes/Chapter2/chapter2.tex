\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}
\stepcounter{chapter}

\begin{document}




\chapter{Differentiation}
\section{Notes}
\begin{itemize}
    \item \marginnote{1/10:}Since manifolds look like Euclidean spaces locally, we basically only need to study differentiation on Euclidean spaces.
    \item Set up: Let $U\subset\R^n$ be open, and $f:U\to\R^n$ be a function.
    \item Idea: The derivative of $f$ at some point $\vec{a}\in U$ is "the best linear approximation" to $f$ at $\vec{a}$.
    \item \textbf{Differentiable} (function $f$ at $\vec{a}$): A function $f$ for which there exists a linear transformation $A:\R^n\to\R^m$ such that
    \begin{equation*}
        \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} = \bm{0}
    \end{equation*}
    \item \textbf{Total derivative} (of $f$ at $\vec{a}$): The linear transformation $A$ corresponding to a differentiable function $f$. \emph{Denoted by} $\bm{Df(\vec{a})}$.
    \item Questions to ask:
    \begin{enumerate}
        \item When does the total derivative exist?
        \item When it does exist, can there be multiple?
        \item When it exists and is unique, how do I calculate it?
    \end{enumerate}
    \item Proposition: If $A,B$ are linear transformations that both satisfy the definition, then $A=B$.
    \begin{itemize}
        \item We have
        \begin{align*}
            \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} &= \bm{0}&
            \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-B\vec{h}}{\norm{\vec{h}}} &= \bm{0}
        \end{align*}
        \item It follows by subtracting the right equation above from the left one that
        \begin{equation*}
            \lim_{\vec{h}\to\bm{0}}\frac{A\vec{h}-B\vec{h}}{\norm{\vec{h}}} = \bm{0}
        \end{equation*}
        \item Apply linearity: For an arbitrary $\vec{v}\in\R^n$ and $t\in\R$, $t>0$, we have
        \begin{equation*}
            \frac{A(t\vec{v})-B(t\vec{v})}{t} = A\vec{v}-B\vec{v}
        \end{equation*}
        \item Therefore, since $t\vec{v}\to 0$ as $t\to 0$, we have by the above that
        \begin{align*}
            \bm{0} &= \lim_{t\to 0}\frac{A(t\vec{v})-B(t\vec{v})}{\norm{t\vec{v}}}\\
            &= \lim_{t\to 0}\frac{A\vec{v}-B\vec{v}}{\norm{\vec{v}}}\\
            \bm{0}\cdot\norm{\vec{v}} &= \lim_{t\to 0}(A\vec{v}-B\vec{v})\\
            \bm{0} &= A\vec{v}-B\vec{v}\\
            B\vec{v} &= A\vec{v}
        \end{align*}
    \end{itemize}
    \item Example: Let $f:\R^n\to\R^m$ be linear, i.e., $f(\vec{v})=A\vec{v}$ for some linear transformation $A$. Then for all $\vec{a}\in\R^n$, $Df(\vec{a})=A$ is constant.
    \begin{itemize}
        \item We have from the definition that
        \begin{align*}
            \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} &= \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a})+f(\vec{h})-f(\vec{a})-f(\vec{h})}{\norm{\vec{h}}}\\
            &= \lim_{\vec{h}\to\bm{0}}\frac{\bm{0}}{\norm{\vec{h}}}\\
            &= \bm{0}
        \end{align*}
    \end{itemize}
    \item Theorem: If $f$ is differentiable at $\vec{a}$, then $f$ is continuous at $\vec{a}$.
    \begin{itemize}
        \item By definition, there exists a linear transformation $A$ such that
        \begin{equation*}
            \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} = \bm{0}
        \end{equation*}
        \item Additionally, we have that
        \begin{equation*}
            f(\vec{a}+\vec{h}) = f(\vec{a})+A\vec{h}+\norm{\vec{h}}\left( \frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} \right)
        \end{equation*}
        \item As $\vec{h}\to\bm{0}$, the right-hand side of the above equation goes to $f(\vec{a})$.
        \begin{itemize}
            \item As a linear transformation, $A\vec{h}\to\bm{0}$ as $\vec{h}\to\bm{0}$.
            \item Clearly $\norm{\vec{h}}\to\bm{0}$ as $\vec{h}\to\bm{0}$.
            \item And we have by definition that the last term goes to $\bm{0}$ as $\vec{h}\to\bm{0}$.
        \end{itemize}
        \item Therefore, $f$ is continuous at $\vec{a}$.
    \end{itemize}
    \item Observation: A function $f:U\to\R^m$ is given by an $m$-tuple of functions $f_1:U\to\R$ known as components. $f=(f_1,\dots,f_m)$.
    \item Proposition: $f$ is differentiable at $\vec{a}\in U$ iff each component function $f_i$ is differentiable at $\vec{a}$. In this case,
    \begin{equation*}
        Df(\vec{a}) = (Df_1(\vec{a}),\dots,Df_m(\vec{a}))
    \end{equation*}
    \begin{itemize}
        \item We know that
        \begin{equation*}
            \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} \in \R^m
        \end{equation*}
        \item Thus, the limit is zero iff the limit of each component is zero.
        \item We have that the $i^\text{th}$ component of the vector on the left below is equal to the number on the right; we call the common value $L_i(\vec{h})$.
        \begin{equation*}
            \left( \frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} \right)_i = \frac{f_i(\vec{a}+\vec{h})-f_i(\vec{a})-(A\vec{h})_i}{\norm{\vec{h}}}
        \end{equation*}
        \item The upshot is that $f$ is differentiable at $\vec{a}$ iff $\lim_{\vec{h}\to\bm{0}}L_i(\vec{h})=\bm{0}$ iff the linear transformation $\vec{h}\mapsto(A\vec{h})_i:\R^m\to\R$ is the total derivative of $f_i$.
    \end{itemize}
    \item Now, each $f_i$ is a function of $n$ variables, i.e., $f_i(x_1,\dots,x_n)$ where $x_1,\dots,x_n$ are coordinates on $\R^n$.
    \item \marginnote{1/12:}\textbf{Partial derivative} (of $f$ wrt. $x_i$ at $\vec{a}\in U$): The following quantity. \emph{Denoted by} $\bm{\partial f/\partial x_i}$. \emph{Given by}
    \begin{equation*}
        \pdv{f}{x_i}(\vec{a}) = \lim_{h\to 0}\frac{f(a_1,\dots,a_{i-1},a_i+h,a_{i+1},\dots,a_n)-f(\vec{a})}{h}
    \end{equation*}
    \begin{itemize}
        \item The partial derivative is easy to calculate if you're good at calculating single-variable derivatives.
    \end{itemize}
    \item Questions:
    \begin{enumerate}
        \item If the partial derivatives all exist, does the total derivative also exist?
        \item If partial derivatives exist, is $f$ continuous?
    \end{enumerate}
    \item The answer is no to both --- it's too weak a condition.
    \begin{itemize}
        \item Counter example: Consider $f:\R^2\to\R$ given by
        \begin{equation*}
            f(x,y) =
            \begin{cases}
                \frac{x^2y}{x^4+y^4} & (x,y)\neq\bm{0}\\
                0 & (x,y)=\bm{0}
            \end{cases}
        \end{equation*}
        \item All partial derivatives exist at $(0,0)$ but $f$ is not continuous at $(0,0)$.
        \item We'll consider this in the homework.
    \end{itemize}
    \item Now we try taking derivatives in infinitely many directions, as opposed to just $n$ many.
    \item \textbf{Directional derivative} (of $f$ at $\vec{a}$ in the direction of $\vec{v}\in\R^n$): The following quantity. \emph{Denoted by} $\bm{D_\vec{v}f(\vec{a})}$, $\bm{\partial f/\partial\vec{v}}$. \emph{Given by}
    \begin{equation*}
        D_\vec{v}f(\vec{a}) = \pdv{f}{\vec{v}} = \lim_{h\to 0}\frac{f(\vec{a}+h\vec{v})-f(\vec{a})}{h}
    \end{equation*}
    \begin{itemize}
        \item We always take $\norm{\vec{v}}=1$.
        \item The partial derivative is just a directional derivative along the standard basis vectors. Alternatively, the directional derivative is just a generalization of the partial derivatives.
    \end{itemize}
    \item This still isn't a strong enough condition --- the above counterexample has all directional derivatives at $(0,0)$ but still isn't continuous.
    \item Proposition: Suppose $f$ is differentiable at $\vec{a}\in U$. Then all directional derivatives of $f$ at $\vec{a}$ exist and for all $\vec{v}\in\R^n$,
    \begin{equation*}
        \pdv{f}{\vec{v}}(\vec{a}) = Df(\vec{a})(\vec{v})
    \end{equation*}
    \begin{itemize}
        \item The total derivative says that the derivative exists from all sequences of approach. We're just going to pick a particular vector direction of approach.
        \item Mathematically, by the definition of the total derivative,
        \begin{align*}
            \bm{0} &= \lim_{h\to 0}\frac{f(\vec{a}+h\vec{v})-f(\vec{a})-Df(\vec{a})(h\vec{v})}{h}\\
            &= \lim_{h\to 0}\frac{f(\vec{a}+h\vec{v})-f(\vec{a})}{h}-Df(\vec{a})(\vec{v})\\
            Df(\vec{a})(\vec{v}) &= \pdv{f}{\vec{v}}
        \end{align*}
    \end{itemize}
    \item A particular consequence is that
    \begin{equation*}
        \pdv{f}{x_i}(\vec{a}) = Df(\vec{a})(e_i)
    \end{equation*}
    \begin{itemize}
        \item But the total derivative, as a linear transformation, is completely defined by its behavior on the basis vectors.
        \item Thus, it is defined by the $m$-by-$n$ matrix
        \begin{equation*}
            Df(\vec{a}) = \left( \pdv{f_j}{x_i} \right)_{\substack{1\leq j\leq m\\1\leq i\leq n}}
        \end{equation*}
    \end{itemize}
    \item \textbf{Jacobian matrix} (of $f$ at $\vec{a}$): The above matrix, representing the total derivative of $f$ at $\vec{a}$.
    \item Theorem: Suppose $f:U\to\R^m$ is a function on an open set $U\subset\R^n$. If all partial derivatives of $f$ exist and are continuous on $U$, then $f$ is differentiable on $U$.
    \begin{itemize}
        \item Recall the mean value theorem (MVT): Suppose $g:[a,b]\to\R$ is a continuous function which is differentiable on $(a,b)$. Then there exists $c\in(a,b)$ such that $g'(c)=[g(b)-g(a)]/[b-a]$.
        \item WLOG let $m=1$ (if we prove this case, we can use the proposition relating $f$ to its components to prove the general case).
        \item Rewrite
        \begin{equation*}
            \begin{split}
                f(\vec{a}+\vec{h})-f(\vec{a}) ={}& f(a_1+h_1,a_2+h_2,a_3+h_3,\dots,a_n+h_n)-f(a_1,a_2+h_2,a_3+h_3,\dots,a_n+h_n)\\
                &+ f(a_1,a_2+h_2,a_3+h_3,\dots,a_n+h_n)-f(a_1,a_2,a_3+h_3,\dots,a_n+h_n)\\
                &+ \cdots\\
                &+ f(a_1,\dots,a_{n-1},a_n+h_n)-f(\vec{a})
            \end{split}
        \end{equation*}
        where $\vec{a}=(a_1,\dots,a_n)$ and $\vec{h}=(h_1,\dots,h_n)$.
        \item Apply the MVT to each term to get
        \begin{equation*}
            f(a_1,\dots,a_i+h_i,\dots,a_n+h_n)-f(a_1,\dots,a_i,\dots,a_n+h_n) = h_i{\pdv{f}{x_i}}(a_1,\dots,c_i(\vec{h}),\dots,a_n+h_n)
        \end{equation*}
        for some $c_i(\vec{h})\in(a_i,a_i+h_i)\cup(a_i+h_i,a_i)$.
        \item Now let $A$ be the Jacobian matrix of $f$ at $\vec{a}$.
        \item WTS:
        \begin{equation*}
            \lim_{\vec{h}\to\bm{0}}\frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} = \bm{0}
        \end{equation*}
        \item We have
        \begin{equation*}
            f(\vec{a}+\vec{h})-f(\vec{a}) = \sum_{i=1}^nh_i{\pdv{f}{x_i}}(a_1,\dots,c_i(\vec{h}),\dots,a_n+h_n)
        \end{equation*}
        \item Let $\pi_i:\R^n\to\R^n$ be the linear map $(x_1,\dots,x_n)\mapsto(0,\dots,x_i,\dots,0)$. Clearly, $\vec{x}=\sum_{i=1}^n\pi_i\vec{x}$.
        \item Thus, $A\vec{h}=\sum_{i=1}^nA\pi_i\vec{h}$ and $A\pi_i\vec{h}={\pdv{f}{x_i}}(\vec{a})\cdot h_i$.
        \item Applying, we have
        \begin{align*}
            \frac{f(\vec{a}+\vec{h})-f(\vec{a})-A\vec{h}}{\norm{\vec{h}}} &= \sum_{i=1}^n\frac{1}{\norm{\vec{h}}}\left( h_i{\pdv{f}{x_i}}(a_1,\dots,a_{i-1},c_i(\vec{h}),a_{i+1}+h_{i+1},\dots,a_n+h_n)-{\pdv{f}{x_i}}(\vec{a})\cdot h_i \right)\\
            &= \sum_{i=1}^n\frac{h_i}{\norm{\vec{h}}}\left( {\pdv{f}{x_i}}(a_1,\dots,a_{i-1},c_i(\vec{h}),a_{i+1}+h_{i+1},\dots,a_n+h_n)-{\pdv{f}{x_i}}(\vec{a}) \right)
        \end{align*}
        \item We know that $-1\leq h_i/\norm{\vec{h}}\leq 1$, so we need only show that the difference above goes to zero as $\vec{h}\to\bm{0}$. But we know this by the continuity of the partial derivatives.
    \end{itemize}
    \item Note that this theorem gives a sufficient condition but not a necessary condition for $f$ to be differentiable.
    \item \marginnote{1/14:}Theorem (Chain Rule): Suppose $f:U\to\R^m$ and $g:V\to\R^p$ are functions defined on open sets $U\subset\R^n$, $V\subset\R^m$ with $f(U)\subset V$. Suppose that $f$ is differentiable at $\vec{a}\in U$ and $g$ is differentiable at $\vec{b}=f(\vec{a})\in V$. Then the composite function $g\circ f:U\to\R^p$ is differentiable at $\vec{a}$ and $D(g\circ f)(\vec{a})=Dg(\vec{b})\circ Df(\vec{a}):\R^n\to\R^p$.
    \begin{itemize}
        \item Note that $f:U\to\R^m$ is differentiable at $\vec{a}\in U$ with derivative $A$ iff $f(\vec{a}+\vec{h})=f(\vec{a})+A\vec{h}+\tilde{f}(\vec{h})$ such that
        \begin{equation*}
            \lim_{\vec{h}\to\bm{0}}\frac{\tilde{f}(\vec{h})}{\norm{\vec{h}}} = \bm{0}
        \end{equation*}
        where $\tilde{f}$ is an error function.
        \begin{itemize}
            \item We're just rearranging terms here.
            \item If you like, $\tilde{f}$ is the numerator from the definition of the total derivative.
        \end{itemize}
        \item Let $A=Df(\vec{a})$, $B=Dg(\vec{b})$. Then
        \begin{equation*}
            f(\vec{a}+\vec{h}) = f(\vec{a})+A\vec{h}+\tilde{f}(\vec{h})
        \end{equation*}
        so
        \begin{align*}
            (g\circ f)(\vec{a}+\vec{h}) &= g(f(\vec{a}+\vec{h}))\\
            &= g(f(\vec{a}))+A\vec{h}+\tilde{f}(\vec{h})\\
            &= g(f(\vec{a}))+B(A\vec{h}+\tilde{f}(\vec{h}))+\tilde{g}(A\vec{h}+\tilde{f}(\vec{h}))\\
            &= g(f(\vec{a}))+BA\vec{h}+B\tilde{f}(\vec{h})+\tilde{g}(A\vec{h}+\tilde{f}(\vec{h}))
        \end{align*}
        \item WTS: $\lim_{\vec{h}\to\bm{0}}[B\tilde{f}(\vec{h})+\tilde{g}(A\vec{h}+\tilde{f}(\vec{h}))]/\norm{\vec{h}}=\bm{0}$.
        \item For the first half of the fraction,
        \begin{equation*}
            \frac{B\tilde{f}(\vec{h})}{\norm{\vec{h}}} = B\left( \frac{\tilde{f}(\vec{h})}{\norm{\vec{h}}} \right) \to \bm{0}
        \end{equation*}
        as $\vec{h}\to\bm{0}$ since the argument goes to $\bm{0}$ as $\vec{h}\to\bm{0}$ and $B$ is a linear transformation (in particular, $B(\vec{0})=\vec{0}$).
        \item For the second half of the fraction,
        \begin{equation*}
            \lim_{\vec{h}\to\bm{0}}\frac{\tilde{g}(A\vec{h}+\tilde{f}(\vec{h}))}{\norm{\vec{h}}} = \lim_{\vec{h}\to\bm{0}}\frac{\tilde{g}(A\vec{h}+\tilde{f}(\vec{h}))}{\norm{A\vec{h}+\tilde{f}(\vec{h})}}\cdot\frac{\norm{A\vec{h}+\tilde{f}(\vec{h})}}{\norm{\vec{h}}}
        \end{equation*}
        \begin{itemize}
            \item The left fraction on the right side of the equality goes to zero as $\vec{h}\to\bm{0}$ by the definition of $\tilde{g}$.
            \item The right fraction on the right side of the equality is bounded since
            \begin{equation*}
                \frac{\norm{A\vec{h}+\tilde{f}(\vec{h})}}{\norm{\vec{h}}} \leq \frac{\norm{A\vec{h}}}{\norm{\vec{h}}}+\frac{\norm{\tilde{f}(\vec{h})}}{\norm{\vec{h}}}
                \leq \norm{A}+\frac{\norm{\tilde{f}(\vec{h})}}{\norm{\vec{h}}}
            \end{equation*}
            where $\norm{A}$ is the operator norm and $\norm{\tilde{f}(\vec{h})}/\norm{\vec{h}}\to 0$ as $\vec{h}\to\bm{0}$ by the definition of $\tilde{f}$.
            \item Thus, the second half of the fraction goes to zero as well.
        \end{itemize}
    \end{itemize}
    \item Theorem: Let $U\subset\R^m$ be an open subset.
    \begin{enumerate}
        \item Suppose $f,g:U\to\R^m$ are functions that are differentiable at $\vec{a}\in U$. Then $f+g$ is also differentiable at $\vec{a}\in U$ and
        \begin{equation*}
            D(f+g)(\vec{a}) = Df(\vec{a})+Dg(\vec{a})
        \end{equation*}
        \item Suppose $f,g:U\to\R$ are both differentiable at $\vec{a}\in U$. Then $f\cdot g$ is also differentiable at $\vec{a}$, and
        \begin{equation*}
            D(f\cdot g)(\vec{a}) = Df(\vec{a})\cdot g(\vec{a})+f(\vec{a})\cdot Dg(\vec{a})
        \end{equation*}
        \item Suppose $f:U\to\R$ is differentiable at $\vec{a}\in U$ and $f(\vec{a})\neq 0$. Then $1/f$ is differentiable at $\vec{a}\in U$ and
        \begin{equation*}
            D(1/f)(\vec{a}) = -\frac{Df(\vec{a})}{f(\vec{a})^2}
        \end{equation*}
    \end{enumerate}
    \begin{itemize}
        \item Proof of 1: Consider the functions $F:U\to\R^{2m}$ and $G:\R^m\times\R^m\to\R^m$ defined by
        \begin{align*}
            F(\vec{x}) &= (f(\vec{x}),g(\vec{x}))&
            G(\vec{y},\vec{z}) &= \vec{y}+\vec{z}
        \end{align*}
        so that
        \begin{equation*}
            f+g = G\circ F
        \end{equation*}
        \begin{itemize}
            \item $F$ is differentiable because its components are differentiable.
            \item $G$ is differentiable because it's linear. This also implies that $DG(\vec{x})=G$.
            \item Apply the chain rule to learn that $G\circ F$ is differentiable with derivative
            \begin{align*}
                D(f+g)(\vec{a}) &= D(G\circ F)(\vec{a})\\
                &= DG(F(\vec{a}))\circ DF(\vec{a})\\
                &= G(DF(\vec{a}))\\
                &= G(Df(\vec{a}),Dg(\vec{a}))\\
                &= Df(\vec{a})+Dg(\vec{a})
            \end{align*}
        \end{itemize}
        \item Prove the others the same way.
    \end{itemize}
    \item Theorem (Mean Value Theorem): Suppose $f:U\to\R$ is differentiable for all $\vec{a}\in U$ and that $U$ contains the line segment joining $\vec{a},\vec{a}+\vec{h}\in U$. Then there exists $t_0\in(0,1)$ such that
    \begin{equation*}
        f(\vec{a}+\vec{h})-f(\vec{a}) = Df(\vec{a}+t_0\vec{h})(\vec{h})
    \end{equation*}
    \begin{itemize}
        \item Define $\phi(t)=f(\vec{a}+t\vec{h})$ for $t\in[0,1]$.
        \item Apply the usual MVT to $\phi$ to learn that there exists $t_0\in(0,1)$ such that $\phi(1)-\phi(0)=\phi'(t_0)$.
        \item Then using the chain rule, $\phi'(t_0)=Df(\vec{a}+t_0\vec{h})(\vec{h})$.
    \end{itemize}
    \item We now discuss higher order derivatives.
    \item \textbf{Differentiable} ($f$ on $U$): A function $f$ that is differentiable at every $\vec{a}\in U$.
    \item If $f$ is differentiable on $U$, then the total derivative gives a map $Df:U\to\lin{\R^n}{\R^m}$.
    \begin{itemize}
        \item Note that $\lin{\R^n}{\R^m}$ is isomorphic to the set of all $m$-by-$n$ matrices, and $\R^{mn}$.
    \end{itemize}
    \item We can ask for $Df$ to itself be differentiable. We define
    \begin{equation*}
        D^2f = D(Df)
    \end{equation*}
    if it exists and, more generally,
    \begin{equation*}
        D^kf = D(D^{k-1}f)
    \end{equation*}
    \item \textbf{Class $\bm{C^k}$} (function): A function $f:U\to\R^m$ for which $Df,\dots,D^kf$ all exist and are continuous on $U$.
    \begin{itemize}
        \item Note that we technically need only require that $D^kf$ exist, as this implies the existence of $Df,\dots,D^{k-1}f$.
        \item A function $f:U\to\R^m$ is of class $C^k$ iff all partial derivatives $\pdv*{f}{x_i}:U\to\R^m$ exist and are of class $C^{k-1}$ (this follows from the theorem relating partial derivatives and differentiability).
    \end{itemize}
    \item \textbf{Smooth} (function): A function of class $C^\infty$.
\end{itemize}



% \section{Office Hours (Rozenblyum)}
% \begin{itemize}
%     \item Intuition for the total derivative?
%     \item Correct domain for $F$ in the sum, product, reciprocal rule theorem?
%     \item Why is it not necessary for $\vec{v}$ in the definition of the directional derivative to be a unit vector? Are we defining multiple directional derivatives in each direction, one for each scalar multiple of a given unit vector?
% \end{itemize}



\section{Chapter 2: Differentiation}
\emph{From \textcite{bib:Munkres}.}
\begin{itemize}
    \item \marginnote{1/18:}\textbf{Directional derivative} (of $f$ at $\vec{a}$ with respect to $\vec{u}$): The following limit, where $A\subset\R^m$ contains a neighborhood of $\vec{a}$, $f:A\to\R^n$, and $\vec{u}\in\R^m$ is nonzero. \emph{Denoted by} $\bm{f'(\vec{a};\vec{u})}$. \emph{Given by}
    \begin{equation*}
        f'(\vec{a};\vec{u}) = \lim_{t\to 0}\frac{f(\vec{a}+t\vec{u})-f(\vec{a})}{t}
    \end{equation*}
    \begin{itemize}
        \item Note that it is not necessary for $\vec{u}$ to be a unit vector.
    \end{itemize}
    \item If we choose as our definition of differentiability "$f$ is differentiable at $\vec{a}$ if $f'(\vec{a};\vec{u})$ exists for every $\vec{u}\neq\bm{0}$," we would not have results such as differentiability implies continuity and the chain rule.
    \begin{itemize}
        \item Thus, we need a stronger definition.
    \end{itemize}
    \item As an alternate definition of differentiability in the one-variable case, consider the following.
    \item \textbf{Differentiable} (single-variable real function at $a$): A function $\phi:A\to\R$, where $A\subset\R$ contains a neighborhood of $a$, for which there exists a number $\lambda$ such that
    \begin{equation*}
        \frac{\phi(a+t)-\phi(a)-\lambda t}{t} \to 0
        \quad\text{as}\quad
        t \to 0
    \end{equation*}
    \item \textbf{Derivative} (of a single-variable real function at $a$): The unique number $\lambda$ in the above definition. \emph{Denoted by} $\phi'(a)$.
    \item "This formulation of the definition makes explicit the fact that if $\phi$ is differentiable, then the linear function $\lambda t$ is a good approximation to the \textbf{increment function} $\phi(a+t)-\phi(a)$; we often call $\lambda t$ the \textbf{first-order approximation} or \textbf{linear approximation} to the increment function" \parencite[43]{bib:Munkres}.
    \item \textbf{Increment function}: The function $\phi(a+t)-\phi(a)$.
    \item \textbf{First-order approximation}: The function $\lambda t$. \emph{Also known as} \textbf{linear approximation}.
    \item To generalize the idea of a first-order/linear approximation to the increment function $f(\vec{a}+\vec{h})-f(\vec{a})$, we take a function that is linear in the sense of linear algebra.
    \item Note that either the sup norm or the Euclidean norm can be used in the definition of the total derivative.
    \item Theorem 5.1: Let $A\subset\R^m$, and let $f:A\to\R^n$. If $f$ is differentiable at $\vec{a}$, then all the directional derivatives of $f$ at $\vec{a}$ exist, and
    \begin{equation*}
        f'(\vec{a};\vec{u}) = Df(\vec{a})\cdot\vec{u}
    \end{equation*}
    \item Theorem 5.2: Let $A\subset\R^m$, and let $f:A\to\R^n$. If $f$ is differentiable at $\vec{a}$, then $f$ is continuous at $\vec{a}$.
    \item \textbf{$\bm{j^\textbf{th}}$ partial derivative} (of $f$ at $\vec{a}$): The directional derivative of $f$ at $\vec{a}$ with respect to the vector $\vec{e}_j$, provided this derivative exists. \emph{Denoted by} $\bm{D_jf(\vec{a})}$.
    \item Theorem 5.3. Let $A\subset\R^m$, and let $f:A\to\R$. If $f$ is differentiable at $\vec{a}$, then
    \begin{equation*}
        Df(\vec{a}) =
        \begin{bmatrix}
            D_1f(\vec{a}) & \cdots & D_mf(\vec{a})\\
        \end{bmatrix}
    \end{equation*}
    \item Theorem 5.4: Let $A\subset\R^m$, and let $f:A\to\R^n$. Suppose $A$ contains a neighborhood of $\vec{a}$. Let $f_i:A\to\R$ be the $i^\text{th}$ component function of $f$ so that
    \begin{equation*}
        f(\vec{x}) =
        \begin{bmatrix}
            f_1(\vec{x})\\
            \vdots\\
            f_n(\vec{x})\\
        \end{bmatrix}
    \end{equation*}
    \begin{enumerate}[label={(\alph*)}]
        \item The function $f$ is differentiable at $\vec{a}$ if and only if each component function $f_i$ is differentiable at $\vec{a}$.
        \item If $f$ is differentiable at $\vec{a}$, then its derivative is the $n$-by-$m$ matrix whose $i^\text{th}$ row is the derivative of the function $f_i$, i.e.,
        \begin{equation*}
            Df(\vec{a}) =
            \begin{bmatrix}
                Df_1(\vec{a})\\
                \vdots\\
                Df_n(\vec{a})\\
            \end{bmatrix}
        \end{equation*}
        or, in other words, $Df(\vec{a})$ is the matrix whose entry in row $i$ and column $j$ is $D_jf_i(\vec{a})$.
    \end{enumerate}
    \item "It is possible for the partial derivatives, and hence the Jacobian matrix, to exist \emph{without} it following that $f$ is differentiable at $\vec{a}$" \parencite[47]{bib:Munkres}.
    \begin{itemize}
        \item As per the example outlined in class.
    \end{itemize}
    \item Special cases ($m=1$ or $n=1$).
    \begin{itemize}
        \item If $f:\R^1\to\R^3$, $f$ is often interpreted as a parameterized curve and
        \begin{equation*}
            \renewcommand{\arraystretch}{1.2}
            Df(t) =
            \begin{bmatrix}
                f_1'(t)\\
                f_2'(t)\\
                f_3'(t)\\
            \end{bmatrix}
        \end{equation*}
        is the velocity vector of the curve.
        \item If $g:\R^3\to\R^1$, $g$ is often interpreted as a scalar field, and the vector field
        \begin{equation*}
            Dg(\vec{x}) =
            \begin{bmatrix}
                D_1g(\vec{x}) & D_2g(\vec{x}) & D_3g(\vec{x})\\
            \end{bmatrix}
        \end{equation*}
        is called the gradient of $g$.
        \begin{itemize}
            \item In this case, the directional derivative of $g$ with respect to $\vec{u}$ is written in calculus as the dot product of the vectors $\stackrel{\rightarrow}{\nabla}g$ and $\vec{u}$.
        \end{itemize}
    \end{itemize}
    \item Theorem 6.1 (Mean Value Theorem): If $\phi:[a,b]\to\R$ is continuous at each point of the closed interval $[a,b]$, and differentiable at each point of the open interval $(a,b)$, then there exists a point $c$ of $(a,b)$ such that
    \begin{equation*}
        \phi(b)-\phi(a) = \phi'(c)(b-a)
    \end{equation*}
    \item Theorem 6.2: Let $A$ be open in $\R^m$. Suppose that the partial derivatives $D_jf_i(\vec{x})$ of the component functions of $f$ exist at each point $\vec{x}$ of $A$ and are continuous on $A$. Then $f$ is differentiable at each point of $A$.
    \item \textbf{Continuously differentiable} (function on $A$): A function $f$ for which the partial derivatives $D_jf_i(\vec{x})$ of the component functions of $f$ exist at each point $\vec{x}\in A$ and are continuous on $A$, where $A\subset\R^m$ is open. \emph{Also known as} \textbf{class $\bm{C^1}$} (function on $A$).
    \item There are differentiable functions that are not of class $C^1$, but we will not concern ourselves with them.
    \item Theorem 6.3\footnote{See Theorem 15.3 in \textcite{bib:CAAGThomasNotes}.}: Let $A$ be open in $\R^m$, and let $f:A\to\R$ be a function of class $C^2$ on $A$. Then for each $\vec{a}\in A$,
    \begin{equation*}
        D_kD_jf(\vec{a}) = D_jD_kf(\vec{a})
    \end{equation*}
    \item Theorem 7.1 (Chain Rule): Let $A\subset\R^m$, $B\subset\R^n$, $f:A\to\R^n$, $g:B\to\R^p$, $f(A)\subset B$, and $\vec{b}=f(\vec{a})$. If $f$ is differentiable at $\vec{a}$ and $g$ is differentiable at $\vec{b}$, then the composite function $g\circ f$ is differentiable at $\vec{a}$. Furthermore,
    \begin{equation*}
        D(g\circ f)(\vec{a}) = Dg(\vec{b})\cdot Df(\vec{a})
    \end{equation*}
    where the indicated product is matrix multiplication.
    \item Corollary 7.2: Let $A$ be open in $\R^m$, and let $B$ be open in $\R^n$. Let $f:A\to\R^n$ and $g:B\to\R^p$ with $f(A)\subset B$. If $f$ and $g$ are of class $C^r$, so is the composite function $g\circ f$.
    \item Theorem 7.3 (Mean Value Theorem): Let $A$ be open in $\R^m$, and let $f:A\to\R$ be differentiable on $A$. If $A$ contains the line segment with end points $\vec{a}$ and $\vec{a}+\vec{h}$, then there is a point $\vec{c}=\vec{a}+t_0\vec{h}$ with $0<t_0<1$ of this line segment such that
    \begin{equation*}
        f(\vec{a}+\vec{h})-f(\vec{a}) = Df(\vec{c})\cdot\vec{h}
    \end{equation*}
    \item Theorem 7.4: Let $A$ be open in $\R^n$, $f:A\to\R^n$, and $\vec{b}=f(\vec{a})$. Suppose that $g$ maps a neighborhood of $\vec{b}$ into $\R^n$, that $g(\vec{b})=\vec{a}$, and $g(f(\vec{x}))=\vec{x}$ for all $\vec{x}$ in a neighborhood of $\vec{a}$. If $f$ is differentiable at $\vec{a}$ and if $g$ is differentiable at $\vec{b}$, then
    \begin{equation*}
        Dg(\vec{b}) = [Df(\vec{a})]^{-1}
    \end{equation*}
    \begin{proof}
        Let $i:\R^n\to\R^n$ be the identity function. It has total derivative $I_n$. But since $g(f(\vec{x}))=i(\vec{x})$ for all $\vec{x}$ in a neighborhood of $\vec{a}$, the Chain Rule implies that
        \begin{align*}
            Dg(\vec{b})\cdot Df(\vec{a}) &= I_n\\
            Dg(\vec{b}) &= [Df(\vec{a})]^{-1}
        \end{align*}
        as desired.
    \end{proof}
    \item It follows from Theorem 7.4 that for $f^{-1}$ to be differentiable at $\vec{a}$, it is \emph{necessary} that $Df(\vec{a})$ is invertible.
    \begin{itemize}
        \item We will later prove that this condition is also \emph{sufficient} for a function $f$ of class $C^1$ to have a differentiable inverse.
    \end{itemize}
    \item \textbf{Functional notation}: Notation such as $\phi'$ for a derivative.
    \item \textbf{Operator notation}: Notation such as $D\phi$ for a derivative.
    \item \textcite{bib:Munkres} argues that Leibniz notation is a relic of a "time when the focus of every physical and mathematical problem was on the \emph{variables} involved, and when \emph{functions} as such were hardly even thought about" (p. 60).
\end{itemize}




\end{document}